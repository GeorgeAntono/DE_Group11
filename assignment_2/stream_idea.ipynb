{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import window, col, avg, concat, lit, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"Lab9_Ex3\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "\n",
    "# Define the PySpark schema for the streaming data\n",
    "data_schema = StructType([\n",
    "    StructField(\"Address\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Price\", IntegerType(), True),\n",
    "    StructField(\"Lot_size\", StringType(), True),\n",
    "    StructField(\"Living_space_size\", StringType(), True),\n",
    "    StructField(\"Build_year\", StringType(), True),\n",
    "    StructField(\"Build_type\", StringType(), True),\n",
    "    StructField(\"House_type\", StringType(), True),\n",
    "    StructField(\"Roof\", StringType(), True),\n",
    "    StructField(\"Rooms\", StringType(), True),\n",
    "    StructField(\"Toilet\", StringType(), True),\n",
    "    StructField(\"Floors\", StringType(), True),\n",
    "    StructField(\"Energy_label\", StringType(), True),\n",
    "    StructField(\"Position\", StringType(), True),\n",
    "    StructField(\"Garden\", StringType(), True),\n",
    "    StructField(\"Estimated_neighbourhood_price_per\", StringType(), True),\n",
    "    StructField(\"Availability\", BooleanType(), True),\n",
    "    StructField(\"event_time\",TimestampType(), True),\n",
    "])\n",
    "\n",
    "# Read the whole dataset as a batch\n",
    "kafkaStream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9093\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .option(\"subscribe\", \"mock\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "df = kafkaStream.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "df1 = df.select(from_json(df.value, data_schema.simpleString()))\n",
    "\n",
    "df1.printSchema()\n",
    "\n",
    "sdf = df1.select(col(\"from_json(value).*\"))\n",
    "\n",
    "sdf.printSchema()\n",
    "\n",
    "# Filter data based on a given price X\n",
    "price_threshold = 500000  # Set your price threshold\n",
    "\n",
    "top_10_prices_df = sdf \\\n",
    "    .groupBy(window(col(\"event_time\"), \"10 seconds\"), \"Price\",\"Availability\") \\\n",
    "    .agg(F.max(\"event_time\").alias(\"latest_event_time\")) \\\n",
    "    .where((col(\"Price\") <= price_threshold) & (col(\"Availability\") == True) )\\\n",
    "    .orderBy(\"Price\", ascending=False) \\\n",
    "    .limit(10)\n",
    "\n",
    "# Update the Availability column based on specific conditions\n",
    "'''updated_data_df = sdf \\\n",
    "    .join(top_10_prices_df.withColumn(\"Price\")) \\\n",
    "    .filter(\"event_time = top_event_time or top_event_time is null\") \\\n",
    "    .withColumn(\"Availability\", F.when(col(\"Availability\") == True, False).otherwise(col(\"Availability\")))'''\n",
    "\n",
    "'''query = resultdf \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9093\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/checkpoint/priceavg\") \\\n",
    "    .option(\"topic\", \"mock\") \\\n",
    "    .option(\"price\", \"price_avg_query\")\\\n",
    "    .outputMode(\"update\") \\\n",
    "    .start()'''\n",
    "\n",
    "query = top_10_prices_df \\\n",
    "    .writeStream \\\n",
    "    .queryName(\"top10_price_window\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .start()\n",
    "\n",
    "try:\n",
    "    for x in range(100):\n",
    "        spark.sql(\"SELECT * FROM top10_price_window\").show()\n",
    "        sleep(10)\n",
    "except KeyboardInterrupt:\n",
    "    query.stop()\n",
    "    # Stop the spark context\n",
    "    spark.stop()\n",
    "    print(\"Stoped the streaming query and the spark context\")\n",
    "\n",
    "'''# Await termination\n",
    "query.awaitTermination()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d63697597c0ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
