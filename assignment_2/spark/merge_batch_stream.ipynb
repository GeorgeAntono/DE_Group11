{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7308d6e-87ae-4e6e-8a96-89f0cb81d449",
   "metadata": {},
   "source": [
    "## Merge the kafka dataset of the right individual with their available houses and outputs into a final bigquery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07dcee3-b9e9-4a5c-a625-ffceadac2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade pip\n",
    "!{sys.executable} -m pip install -q google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bab934-5b4c-441d-9f3c-3924d65fe043",
   "metadata": {},
   "source": [
    "## Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae0cc397-74c1-4c11-b824-089890b34bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"BigqueryExample\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537fd92-d03a-4e70-9164-efadd1c96633",
   "metadata": {},
   "source": [
    "## Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bc1b214-8f76-40cd-82f2-351d7d66049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Price: long (nullable = true)\n",
      " |-- Availability: boolean (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Price: long (nullable = true)\n",
      " |-- Availability: boolean (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      "\n",
      "825276\n"
     ]
    }
   ],
   "source": [
    "# Load data from BigQuery.\n",
    "df_kafka = spark.read \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .load(\" degroup11.group11dataset.house_pricing_kafka\")    \n",
    "\n",
    "df_kafka=df_kafka.drop(\"window\")\n",
    "df_kafka.printSchema()\n",
    "\n",
    "df_batch = spark.read \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .load(\" degroup11.group11dataset.available_houses_for_individual\")  \n",
    "df_batch.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be57c3ea-7a48-498b-b98f-28264d84c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------+------------+--------------------+\n",
      "|             Address|              City| Price|Availability|          event_time|\n",
      "+--------------------+------------------+------+------------+--------------------+\n",
      "|       Aekingaweg 12|         Appelscha|825000|        true|2023-12-05 12:01:...|\n",
      "|        Bikkeldam 24|           Horssen|825000|        true|2023-12-05 12:30:...|\n",
      "|   Bodenheimstraat 5|               Ede|825000|        true|2023-12-05 12:35:...|\n",
      "|Distelvlinderstra...|          Aalsmeer|825000|        true|2023-12-05 13:25:...|\n",
      "|J.W. van Puttestr...|            Ameide|825000|        true|2023-12-05 14:54:...|\n",
      "|  Jos Colerstraat 10|         Rotterdam|825000|        true|2023-12-05 15:05:...|\n",
      "|        Lage Maat 11|Wijk bij Duurstede|825000|        true|2023-12-05 15:44:...|\n",
      "|      Lindestraat 10|    St. Willebrord|825000|        true|2023-12-05 15:57:...|\n",
      "|Maerten van Heems...|         Beverwijk|825000|        true|2023-12-05 16:05:...|\n",
      "|      Molenstraat 47|           Monster|825000|        true|2023-12-05 16:24:...|\n",
      "|    Nieuwehaven 19 C|              Edam|825000|        true|2023-12-05 16:33:...|\n",
      "|      Noordstraat 60|        Bodegraven|825000|        true|2023-12-05 16:38:...|\n",
      "|      Papenstraat 15|          Deventer|825000|        true|2023-12-05 16:54:...|\n",
      "|   Raiffeisenlaan 46|           Utrecht|825000|        true|2023-12-05 17:18:...|\n",
      "|    Viaductstraat 72|             Wamel|825000|        true|2023-12-05 18:38:...|\n",
      "|        Hoepmaker 10|       Papendrecht|820000|        true|2023-12-05 14:37:...|\n",
      "|      Peperstraat 45|             Gouda|815000|        true|2023-12-05 17:02:...|\n",
      "|        't HÃ¶ltje 42|            Helden|800000|        true|2023-12-05 11:55:...|\n",
      "|    Heiblomsedijk 15|          Berlicum|800000|        true|2023-12-05 14:24:...|\n",
      "|      Iepenstraat 18|           Haarlem|800000|        true|2023-12-05 14:50:...|\n",
      "+--------------------+------------------+------+------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "df_combined = df_batch.union(df_kafka)\n",
    "\n",
    "df_combined=df_combined.dropDuplicates([\"Address\", \"Price\"])\n",
    "\n",
    "df_combined = df_combined.orderBy(\"Price\", ascending=False)\n",
    "df_combined.show()\n",
    "df_combined = df_combined.limit(500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c9806-a24b-4166-ae3e-2c16da602443",
   "metadata": {},
   "source": [
    "## Enrich combined dataframe with information about the houses so that Looker Studio can use it, so we don't need blended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d30b8f4d-1ca6-454a-b081-529f82a7c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing = spark.read \\\n",
    "  .format(\"bigquery\") \\\n",
    "  .load(\" degroup11.group11dataset.house_pricing\")    # project_id.datatset.tablename. Use your project id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b2324b7-0c45-43b7-b05a-d2b681f2855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Price: long (nullable = true)\n",
      " |-- Lot_size: string (nullable = true)\n",
      " |-- Living_space_size: string (nullable = true)\n",
      " |-- Build_year: string (nullable = true)\n",
      " |-- Build_type: string (nullable = true)\n",
      " |-- House_type: string (nullable = true)\n",
      " |-- Roof: string (nullable = true)\n",
      " |-- Rooms: string (nullable = true)\n",
      " |-- Toilet: string (nullable = true)\n",
      " |-- Floors: string (nullable = true)\n",
      " |-- Energy_label: string (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- Garden: string (nullable = true)\n",
      " |-- Estimated_neighbourhood_price_per: double (nullable = true)\n",
      " |-- Availability: boolean (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc\n",
    "df_combined_enriched = df_housing.join(df_combined,\\\n",
    "                                        (df_combined.Address == df_housing.Address) \\\n",
    "                                        & (df_combined.City == df_housing.City) \\\n",
    "                                        & (df_combined.Price == df_housing.Price) \\\n",
    "                                        & (df_combined.Availability == df_housing.Availability) \\\n",
    "                                        & (df_combined.event_time == df_housing.event_time), \"leftsemi\")\n",
    "\n",
    "df_combined_enriched = df_combined_enriched.orderBy(col(\"Price\").desc())\n",
    "df_combined_enriched.printSchema()\n",
    "df_combined_enriched.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe3b82-e353-44e8-adc3-ed511de1eef7",
   "metadata": {},
   "source": [
    "## Write merged dataframe of the top available houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225eda4-e1d0-41be-aa1e-ffd89e796876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_enriched.write.format(\"bigquery\").\\\n",
    "option('table', \"degroup11.group11dataset.top_houses\").\\\n",
    "option(\"temporaryGcsBucket\", \"temp_degroup11\"). \\\n",
    "mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b47bb1-291f-4ec1-b9be-1f4863e0a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "#Initialize the BigQuery client\n",
    "client = bigquery.Client(project=\"degroup11\")\n",
    "\n",
    "#Delete temporary kafka table\n",
    "client.delete_table(\"degroup11.group11dataset.house_pricing_kafka\", not_found_ok=True)\n",
    "\n",
    "#Delete temporary batch table\n",
    "client.delete_table(\"degroup11.group11dataset.available_houses_for_individual\", not_found_ok=True)\n",
    "\n",
    "#Delete cookie as session is over\n",
    "client.delete_table(\"degroup11.group11dataset.cookie_ID_houses\", not_found_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fb031-30a9-4585-a3e7-fac413574e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
