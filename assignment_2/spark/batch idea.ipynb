{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501f1b0f-57db-4f13-b027-e78dbd0dffff",
   "metadata": {},
   "source": [
    "# Step 1 of the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ae9de7-e547-420e-ae4f-efc70df49a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.11/site-packages (3.13.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (1.59.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (1.22.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (2.6.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (4.24.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.61.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.23.4)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.59.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.11/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2023.7.22)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e70e07-9f88-470f-8c59-6a55fe0d4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"batch idea\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "df_individuals = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "       .load(\"data/individuals_updated.csv\")\n",
    "\n",
    "df_spouse = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "       .load(\"data/spouse_updated.csv\")\n",
    "\n",
    "df_house = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "       .load(\"data/house_pricing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f848a97d-9df9-4835-8a97-e1601ed19bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- has_spouse: string (nullable = true)\n",
      " |-- spouse_ID: string (nullable = true)\n",
      " |-- gross_salary: string (nullable = true)\n",
      " |-- has_student_loan: string (nullable = true)\n",
      " |-- student_loan_amount: string (nullable = true)\n",
      " |-- has_general_loan: string (nullable = true)\n",
      " |-- general_loan_amount: string (nullable = true)\n",
      " |-- has_alimony: string (nullable = true)\n",
      " |-- alimony_amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_individuals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0fa7b72-602b-4b9e-8cf3-0ec801b12ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, age: string, has_spouse: boolean, spouse_ID: string, gross_salary: int, has_student_loan: string, student_loan_amount: string, has_general_loan: string, general_loan_amount: string, has_alimony: string, alimony_amount: int, spendable_income: int]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edbef132-360a-43a1-81bf-e5ddf65ad897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------+----------------+\n",
      "| ID|has_spouse|gross_salary|alimony_amount|spendable_income|\n",
      "+---+----------+------------+--------------+----------------+\n",
      "|  1|     false|      191453|             0|          191453|\n",
      "|  2|     false|       82586|             0|           82586|\n",
      "|  3|     false|      151688|             0|          151688|\n",
      "|  4|     false|      107499|             0|          107499|\n",
      "|  5|     false|       31355|             0|           31355|\n",
      "|  6|     false|      114946|          1657|           95062|\n",
      "|  7|     false|      193937|             0|          193937|\n",
      "|  8|     false|      108115|           515|          101935|\n",
      "|  9|     false|      168304|             0|          168304|\n",
      "| 10|     false|      137758|           497|          131794|\n",
      "| 11|     false|      156277|             0|          156277|\n",
      "| 12|     false|      119447|             0|          119447|\n",
      "| 13|     false|      111993|             0|          111993|\n",
      "| 14|     false|      123917|             0|          123917|\n",
      "| 15|     false|      133414|           301|          129802|\n",
      "| 16|     false|       96027|             0|           96027|\n",
      "| 17|     false|      102618|           953|           91182|\n",
      "| 18|     false|      145157|             0|          145157|\n",
      "| 19|     false|      157846|             0|          157846|\n",
      "| 20|     false|      174121|             0|          174121|\n",
      "+---+----------+------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df = df_individuals\n",
    "# Convert necessary columns to appropriate data types (e.g., from string to integer/boolean)\n",
    "df = df.withColumn(\"gross_salary\", col(\"gross_salary\").cast(\"int\"))\n",
    "df = df.withColumn(\"alimony_amount\", col(\"alimony_amount\").cast(\"int\"))\n",
    "df = df.withColumn(\"has_spouse\", col(\"has_spouse\") == \"True\")\n",
    "\n",
    "# Apply the formula\n",
    "df = df.withColumn(\"spendable_income\", \n",
    "                   when(col(\"has_spouse\") == False, col(\"gross_salary\") - 12 * col(\"alimony_amount\"))\n",
    "                   .otherwise(col(\"gross_salary\")))\n",
    "\n",
    "# Show the result\n",
    "df.select(\"ID\", \"has_spouse\", \"gross_salary\", \"alimony_amount\", \"spendable_income\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1f8caf9-57c0-437b-87a3-3f28f375cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- has_spouse: string (nullable = true)\n",
      " |-- spouse_ID: string (nullable = true)\n",
      " |-- gross_salary: string (nullable = true)\n",
      " |-- has_student_loan: string (nullable = true)\n",
      " |-- student_loan_amount: string (nullable = true)\n",
      " |-- has_general_loan: string (nullable = true)\n",
      " |-- general_loan_amount: string (nullable = true)\n",
      " |-- has_alimony: string (nullable = true)\n",
      " |-- alimony_amount: string (nullable = true)\n",
      " |-- spouse_ID: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gross_salary: string (nullable = true)\n",
      " |-- has_student_loan: string (nullable = true)\n",
      " |-- student_loan_amount: string (nullable = true)\n",
      " |-- has_general_loan: string (nullable = true)\n",
      " |-- general_loan_amount: string (nullable = true)\n",
      " |-- has_alimony: string (nullable = true)\n",
      " |-- alimony_amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "df_comb = df_individuals.alias(\"ind\").join(df_spouse.alias(\"sp\"), col(\"ind.ID\") ==  col(\"sp.spouse_ID\"),\"inner\")\n",
    "\n",
    "df_comb.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500cb8a-a929-48f0-bf44-5838418477c0",
   "metadata": {},
   "source": [
    "## This is the house mortage amount without taking into account who has the highest salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b63c30c8-2e25-4fff-8f7d-ac5ff9f0d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "|gross_salary|alimony_amount|has_spouse|gross_salary|alimony_amount|house_spendable_income|\n",
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "|      191453|             0|      TRUE|       54528|             0|                209629|\n",
      "|       82586|             0|      TRUE|      144409|   2513.721669|                120667|\n",
      "|      151688|             0|     FALSE|       80291|             0|                151688|\n",
      "|      107499|             0|      TRUE|       33528|             0|                118675|\n",
      "|       31355|             0|      TRUE|      165719|             0|                 86594|\n",
      "|      114946|   1657.604031|     FALSE|      147674|             0|                 95054|\n",
      "|      193937|             0|      TRUE|      158092|             0|                246634|\n",
      "|      108115|   515.4660385|      TRUE|       30499|             0|                112095|\n",
      "|      168304|             0|     FALSE|       60684|             0|                168304|\n",
      "|      137758|   497.8048837|     FALSE|      111405|             0|                131784|\n",
      "|      156277|             0|      TRUE|       36268|             0|                168366|\n",
      "|      119447|             0|     FALSE|      150985|             0|                119447|\n",
      "|      111993|             0|     FALSE|       46571|             0|                111993|\n",
      "|      123917|             0|      TRUE|       56067|             0|                142606|\n",
      "|      133414|   301.6947677|      TRUE|      141513|             0|                176964|\n",
      "|       96027|             0|     FALSE|      123751|             0|                 96027|\n",
      "|      102618|   953.3290723|     FALSE|       51056|             0|                 91178|\n",
      "|      145157|             0|      TRUE|       54717|             0|                163396|\n",
      "|      157846|             0|      TRUE|       39975|             0|                171171|\n",
      "|      174121|             0|      TRUE|       54290|   780.9272571|                189093|\n",
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_comb\n",
    "# Convert necessary columns to appropriate data types (e.g., from string to integer/boolean)\n",
    "df = df.withColumn(\"ind.gross_salary\", col(\"ind.gross_salary\").cast(\"int\"))\n",
    "df = df.withColumn(\"ind.alimony_amount\", col(\"ind.alimony_amount\").cast(\"int\"))\n",
    "df = df.withColumn(\"ind.has_spouse\", col(\"ind.has_spouse\") == \"True\")\n",
    "df = df.withColumn(\"sp.gross_salary\", col(\"sp.gross_salary\").cast(\"int\"))\n",
    "df = df.withColumn(\"sp.alimony_amount\", col(\"sp.alimony_amount\").cast(\"int\"))\n",
    "\n",
    "# Apply the formula\n",
    "df = df.withColumn(\"house_spendable_income\", \n",
    "                   when(col(\"ind.has_spouse\") == False, col(\"ind.gross_salary\") - 12 * col(\"ind.alimony_amount\"))\n",
    "                   .otherwise(col(\"ind.gross_salary\") - 12 * col(\"ind.alimony_amount\")+ 1/3 * (col(\"sp.gross_salary\")-12 * col(\"sp.alimony_amount\"))))\n",
    "\n",
    "df = df.withColumn(\"house_spendable_income\", col(\"house_spendable_income\").cast(\"int\"))\n",
    "#df_comb.select(\"ind.student_loan_amount\", \"sp.student_loan_amount\").show()\n",
    "df.select(\"ind.gross_salary\",\"ind.alimony_amount\",\"ind.has_spouse\",\"sp.gross_salary\",\"sp.alimony_amount\", \"house_spendable_income\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3305a2a-0870-46be-a95e-5932a32c5b82",
   "metadata": {},
   "source": [
    "## Spendable income calculation where the highest income is also taken into account, since only 1/3 of the lower income is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64cd877a-f365-4e23-afb9-b52bb5c5c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "|gross_salary|alimony_amount|has_spouse|gross_salary|alimony_amount|house_spendable_income|\n",
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "|      191453|             0|      TRUE|       54528|             0|                118345|\n",
      "|       82586|             0|      TRUE|      144409|   2513.721669|                120667|\n",
      "|      151688|             0|     FALSE|       80291|             0|                151688|\n",
      "|      107499|             0|      TRUE|       33528|             0|                 69361|\n",
      "|       31355|             0|      TRUE|      165719|             0|                 86594|\n",
      "|      114946|   1657.604031|     FALSE|      147674|             0|                 95054|\n",
      "|      193937|             0|      TRUE|      158092|             0|                246634|\n",
      "|      108115|   515.4660385|      TRUE|       30499|             0|                 64475|\n",
      "|      168304|             0|     FALSE|       60684|             0|                168304|\n",
      "|      137758|   497.8048837|     FALSE|      111405|             0|                131784|\n",
      "|      156277|             0|      TRUE|       36268|             0|                 88360|\n",
      "|      119447|             0|     FALSE|      150985|             0|                119447|\n",
      "|      111993|             0|     FALSE|       46571|             0|                111993|\n",
      "|      123917|             0|      TRUE|       56067|             0|                 97372|\n",
      "|      133414|   301.6947677|      TRUE|      141513|             0|                184777|\n",
      "|       96027|             0|     FALSE|      123751|             0|                 96027|\n",
      "|      102618|   953.3290723|     FALSE|       51056|             0|                 91178|\n",
      "|      145157|             0|      TRUE|       54717|             0|                103102|\n",
      "|      157846|             0|      TRUE|       39975|             0|                 92590|\n",
      "|      174121|             0|      TRUE|       54290|   780.9272571|                102959|\n",
      "+------------+--------------+----------+------------+--------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_comb\n",
    "# Convert necessary columns to appropriate data types (e.g., from string to integer/boolean)\n",
    "df = df.withColumn(\"ind.gross_salary\", col(\"ind.gross_salary\").cast(\"int\"))\n",
    "df = df.withColumn(\"ind.alimony_amount\", col(\"ind.alimony_amount\").cast(\"int\"))\n",
    "df = df.withColumn(\"ind.has_spouse\", col(\"ind.has_spouse\") == \"True\")\n",
    "\n",
    "df = df.withColumn(\"sp.gross_salary\", col(\"sp.gross_salary\").cast(\"int\"))\n",
    "df = df.withColumn(\"sp.alimony_amount\", col(\"sp.alimony_amount\").cast(\"int\"))\n",
    "                   \n",
    "# Apply the formula\n",
    "df = df.withColumn(\"house_spendable_income\", \n",
    "                   when(col(\"ind.has_spouse\") == False, \n",
    "                        col(\"ind.gross_salary\") - 12 * col(\"ind.alimony_amount\"))\n",
    "                   .otherwise(when(col(\"ind.gross_salary\")>col(\"sp.gross_salary\"),col(\"ind.gross_salary\") - 12 * col(\"ind.alimony_amount\")+ 1/3 * (col(\"sp.gross_salary\")-12 * col(\"sp.alimony_amount\")))\\\n",
    "                             .otherwise(col(\"sp.gross_salary\") - 12 * col(\"sp.alimony_amount\")+ 1/3 * (col(\"ind.gross_salary\")-12 * col(\"ind.alimony_amount\")))))\n",
    "\n",
    "df = df.withColumn(\"house_spendable_income\", col(\"house_spendable_income\").cast(\"int\"))\n",
    "#df_comb.select(\"ind.student_loan_amount\", \"sp.student_loan_amount\").show()\n",
    "df.select(\"ind.gross_salary\",\"ind.alimony_amount\",\"ind.has_spouse\",\"sp.gross_salary\",\"sp.alimony_amount\", \"house_spendable_income\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f812c287-4004-4159-a80c-903f475ede32",
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/degroup11/jobs?prettyPrint=false: Access Denied: Project degroup11: User does not have bigquery.jobs.create permission in project degroup11.\n\nLocation: None\nJob ID: 442ff93c-a3cc-49fb-8617-766f1a6c5b76\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Perform a query.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m QUERY \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT * FROM `degroup11.group11dataset.individuals` LIMIT 100\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# use the correct project id, etc.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m query_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQUERY\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# API request\u001b[39;00m\n\u001b[1;32m      5\u001b[0m rows \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult()  \u001b[38;5;66;03m# Waits for query to finish\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/client.py:3391\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[1;32m   3380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[1;32m   3381\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3382\u001b[0m         query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         job_retry,\n\u001b[1;32m   3389\u001b[0m     )\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[0;32m-> 3391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_job_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_jobs_insert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3392\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_id_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/_job_helpers.py:114\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[0;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[0;32m--> 114\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[43mdo_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/_job_helpers.py:91\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1370\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \n\u001b[1;32m   1352\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1370\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1372\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1373\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1374\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/job/base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m--> 693\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.job.begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_api_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/bigquery/client.py:808\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    806\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    807\u001b[0m     ):\n\u001b[0;32m--> 808\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/degroup11/jobs?prettyPrint=false: Access Denied: Project degroup11: User does not have bigquery.jobs.create permission in project degroup11.\n\nLocation: None\nJob ID: 442ff93c-a3cc-49fb-8617-766f1a6c5b76\n"
     ]
    }
   ],
   "source": [
    "# Perform a query.\n",
    "QUERY = (\n",
    "    'SELECT * FROM `degroup11.group11dataset.individuals` LIMIT 100')   # use the correct project id, etc.\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3e15b-a72b-4b02-a7cb-b822c7bb3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job ID: b7f980d4-3f39-4ce8-a54a-7284809f5fa1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90219834-dbaf-43d0-96b3-de51c59c1459",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58a024-28b2-4a06-9d7a-9bb23d5505e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
